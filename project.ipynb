{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fb601b-7584-4567-95f9-9b595cfc7fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset and get the overall information:\n",
    "import pandas as pd\n",
    "df = pd.read_csv('/Users/trangnguyen/Documents/GitHub/PersonalPrj/train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6928d523-3627-46ba-801d-40fbc35e3556",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import seaborn as sns\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib \n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44301b4a-2bbb-4c46-a9b6-4984131c04cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04267f5f-0619-4355-9b0f-34433ab8ff0d",
   "metadata": {},
   "source": [
    "## I. Data Cleaning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a947e6d2-c849-437c-99db-fe89bd13f1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check is is there any null value \n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9170d50-f10c-471e-b4e6-add359710859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show unique Age values\n",
    "df['Age'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d48db1-8b33-4615-b86f-bde753e67e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to shorten the age, if they are 5 digits remove to 2 digits only\n",
    "def shorten_age(age):\n",
    "    if abs(age) >= 1000:\n",
    "        return int(str(age)[:2])  \n",
    "    else:\n",
    "        return age  \n",
    "\n",
    "def positive_age(age):\n",
    "    if age < 0: \n",
    "        return -age\n",
    "    else:\n",
    "        return age\n",
    "\n",
    "df['Age'] = df['Age'].apply(shorten_age).apply(positive_age)\n",
    "print(df['Age'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56038b09-99c1-45db-ac30-b6c590179a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show unique DeviceType values\n",
    "df['DeviceType'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057046ba-4a7d-484f-9d75-3e7dab21ce3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge them into 3 groups: Desktop, Mobile, Table\n",
    "df['DeviceType'] = df['DeviceType'].replace({'mob':'Mobile', 'iphone 15' : 'Mobile', 'android': 'Mobile', 'smartphone': 'Mobile', 'galaxys7': 'Mobile'}) \n",
    "df['DeviceType'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9b5bad-283b-46f4-89b7-ad2b52584a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Gender'] = df['Gender'].replace({'he':'Male', 'man' : 'Male', 'isnotfemale': 'Male'})\n",
    "df['Gender'] = df['Gender'].replace({'fem':'Female', 'isnotmale' : 'Female', 'woman': 'Female', 'she': 'Female'})\n",
    "df['Gender'] = df['Gender'].replace('Male', '0')\n",
    "df['Gender'] = df['Gender'].replace('Female', '1')\n",
    "df['Gender'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a08e505-8ea0-41f7-90dd-e54906fde9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace inconsistent values\n",
    "df['Income'] = df['Income'].str.replace('$','').str.replace( 'AU$' , '').str.replace('AUD' ,'').str.replace('AU', '').astype(float)\n",
    "print(df['Income'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c25dd87-ab82-45ec-949c-8c152b26ae3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Expenditure:\n",
    "df['Expenditure'] = df['Expenditure'].replace({'AU$36604.93': '36604.93'}, regex=True)\n",
    "# Clean the 'Expenditure' column by removing currency symbols and unwanted characters\n",
    "df['Expenditure'] = df['Expenditure'].replace({'AU\\$': '', 'AUD': '', 'AED': '', ' ': ''}, regex=True)\n",
    "\n",
    "# Convert the cleaned column to numeric values\n",
    "df['Expenditure'] = pd.to_numeric(df['Expenditure'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd41ec1-529c-4e3f-a8cc-895b01aca443",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_currency(n):\n",
    "    n = str(n)\n",
    "    \n",
    "    if n.endswith('AUD') or n.startswith('AU$'):\n",
    "        n = n.replace('AU$', '').replace('AUD', '').strip()\n",
    "        try:\n",
    "            n = float(n)\n",
    "            return n / 1.96  \n",
    "        except ValueError:\n",
    "            return None  \n",
    "    else:\n",
    "        n = n.replace('GBP', '').replace('Â£', '').replace('Â¬', '').strip()\n",
    "        try:\n",
    "            n = float(n)\n",
    "            return n\n",
    "        except ValueError:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7365bd59-1d12-47b2-ac72-bf63a8ef5572",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['GiftsTransaction'] = df['GiftsTransaction'].apply(change_currency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24d46ec-59a6-4f57-ac5b-33ce3e5f5121",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TransactionAmount'] = df['TransactionAmount'].replace({'AU\\$': '', 'AUD': '', 'AED': '', ' ': ''}, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b6f108-0730-49a7-a98b-1edd159a1d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('TransactionNumber', axis = 1)\n",
    "df = df.drop('UserID', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a84f34-c8ec-48cc-a3ee-df1f98a80624",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TransactionAmount'] = pd.to_numeric(df['TransactionAmount'], errors='coerce').astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a3cde8-9f37-4e5d-a110-63daf10efe8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394fa07d-8260-4348-853d-d60dd2265177",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('EmailDomain', axis = 1)\n",
    "df = df.drop('Latitude', axis = 1)\n",
    "df = df.drop('Longitude', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38030a2f-91cf-4e42-90a0-8fdd945ea73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a973b7ae-c696-4382-9908-095ba31437b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e932c3f-0ad3-448d-891e-e21b8bf919fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the categorical columns:\n",
    "categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "categorical_columns = categorical_columns.drop('TransactionDate')\n",
    "categorical_columns = categorical_columns.drop('TransactionTime')\n",
    "categorical_columns = categorical_columns.drop('TransactionLocation')\n",
    "categorical_columns = categorical_columns.drop('MerchantID')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6f3bae-e842-47c9-92d9-83d89fbd2292",
   "metadata": {},
   "outputs": [],
   "source": [
    "encode1 = LabelEncoder()\n",
    "df['TransactionLocation'] = encode1.fit_transform(df['TransactionLocation'])\n",
    "df['Terrorism'] = encode1.fit_transform(df[['Terrorism']])\n",
    "df['TransactionDate'] = encode1.fit_transform(df['TransactionDate'])\n",
    "df['TransactionTime'] = encode1.fit_transform(df['TransactionTime'])\n",
    "df['MerchantID'] = encode1.fit_transform(df['MerchantID'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7e42b2-c972-47c0-b1da-20b634ce56b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "df = pd.get_dummies(df, columns=categorical_columns, dtype = int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb931c0a-ad36-40b9-b93f-de782ab2ced4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c85a29-286c-4fe7-83c6-37d7e80640ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71203c5-e815-4900-b56c-a4ebd87b48d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn. linear_model import LogisticRegression \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn. model_selection import train_test_split \n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X = df.drop(columns=['IsFraud']) \n",
    "y = df['IsFraud']  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84bec312-ce5b-4635-9985-cefbe9d34bdd",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a7a582-65d8-4fe9-ac89-497ac06a046e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the StandardScaler for normalization\n",
    "scaler = StandardScaler ()\n",
    "\n",
    "# Normalize the features in X\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "\n",
    "# Create an instance of Logistic Regression\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Fit the model to the training data\n",
    "logreg.fit(X_train_normalized, y_train)\n",
    "\n",
    "# Get the best fitted line:\n",
    "print(\"y = x *\", logreg.coef_, \"+\", logreg.intercept_)\n",
    "\n",
    "# Normalize the features in X\n",
    "X_test_normalized = scaler.fit_transform(X_test)\n",
    "\n",
    "# Testing the model:\n",
    "y_pred = logreg.predict(X_test_normalized)\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(\"F1 Score:\", f1)\n",
    "\n",
    "# Evaluate the model:\n",
    "# Doing evaluation\n",
    "print(\"The accuracy score is: \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd379fd-dc8c-43fc-9d03-fba28bab07fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating RFE object\n",
    "lr_model = LogisticRegression()\n",
    "rfe = RFE(estimator=lr_model, n_features_to_select=3, step=1)\n",
    "rfe.fit(X_train_normalized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b20b06d-863e-4eaa-9154-9d1e777d22d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing evaluation\n",
    "y_test_hat = rfe.predict(X_test_normalized)\n",
    "print(\"The accuracy score is: \", accuracy_score(y_test, y_test_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baae7428-552a-482a-977d-0fa836922b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize all features\n",
    "for i in range(X_train.shape[1]):\n",
    "    print('Column: %d, Selected %s, Rank: %.3f' % (i, rfe.support_[i], rfe.ranking_[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102a1975-896e-4054-9600-7691d2545b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To increment number of features, one at each time\n",
    "acc_scores = []\n",
    "for i in range(1,33):\n",
    "    clf = LogisticRegression()\n",
    "    rfe = RFE(estimator=clf, n_features_to_select=i)\n",
    "    # Training model\n",
    "    rfe.fit(X_train_normalized, y_train)\n",
    "    # Predicting on test set\n",
    "    y_pred = rfe.predict(X_test_normalized)\n",
    "    acc_score = accuracy_score(y_test, y_pred)\n",
    "    # Print this\n",
    "    print(\"Accuracy on test set using\", i, \"features: \", acc_score)\n",
    "    # Append to the list\n",
    "    acc_scores.append(acc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a67334e-a18c-4ea8-b58e-b374d4dd499c",
   "metadata": {},
   "source": [
    "# Estimating accuracy score on test set using RFE by using different number of features\n",
    "estimator = LogisticRegression()\n",
    "acc_scores = []\n",
    "for i in range(1, 33):\n",
    "    selector = RFE(estimator,n_features_to_select=i)\n",
    "    selector = selector.fit(X_train_normalized, y_train)\n",
    "    supp = selector.get_support()\n",
    "\n",
    "    predicted = selector.predict(X_test_normalized)\n",
    "    acc_score = accuracy_score(y_test, predicted)\n",
    "    acc_scores.append(acc_score)\n",
    "\n",
    "best = 1\n",
    "for item1 in acc_scores:\n",
    "    if item1 > acc_scores[best - 1]:\n",
    "        best = acc_scores.index(item1) + 1\n",
    "plt.grid()\n",
    "plt.xlabel('# No. of features')\n",
    "plt.ylabel('Accuracy score on test set')\n",
    "plt.plot(range(1, 33), acc_scores, marker = 'o', color = 'lightblue', markeredgewidth = 1 ,markeredgecolor = 'lightblue', markerfacecolor = 'None')\n",
    "plt.plot(best, acc_scores[best-1], marker = 'o', markerfacecolor = 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ecae76-b2ef-473c-9b71-d05d2f56febc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Logistic Regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_normalized, y_train)\n",
    "# Doing predictions on train and test set\n",
    "y_hat_train = model.predict(X_train_normalized)\n",
    "y_hat_test = model.predict(X_test_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c08d90e-f7c8-44cd-85a4-16db20d7e4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the performance of the trained model\n",
    "print(\"Accuracy score on training set: \", accuracy_score(y_train, y_hat_train))\n",
    "print(\"Accuracy score on testing set: \", accuracy_score(y_test, y_hat_test))\n",
    "# Checking confusion matrix\n",
    "print(\"Confusion matrix on test set: \")\n",
    "print(confusion_matrix(y_test, y_hat_test))\n",
    "print(\"Confusion matrix on train set: \")\n",
    "print(confusion_matrix(y_train, y_hat_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5280d1-a9f5-4e4e-8a50-8d43359901ec",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a72ae8-d81c-40ba-9547-ef458461b361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train a Decision Tree classifier model\n",
    "dtree = DecisionTreeClassifier()\n",
    "dtree.fit(X_train_normalized, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "dtree_y_pred = dtree.predict(X_test_normalized)\n",
    "dtree_accuracy = accuracy_score(y_test, dtree_y_pred)\n",
    "dtree_f1 = f1_score(y_test,dtree_y_pred)\n",
    "print('The accuracy score is:', dtree_accuracy)\n",
    "print('The f1 score is:', dtree_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603437c3-143b-4dbd-97bd-372ddd1bb50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To increment number of features, one at each time\n",
    "acc_scores = []\n",
    "for i in range(1,33):\n",
    "    dt = DecisionTreeClassifier()\n",
    "    rfe_new = RFE(estimator=dt, n_features_to_select=i)\n",
    "    # Training model\n",
    "    rfe_new.fit(X_train_normalized, y_train)\n",
    "    # Predicting on test set\n",
    "    y_pred = rfe_new.predict(X_test_normalized)\n",
    "    acc_score = accuracy_score(y_test, y_pred)\n",
    "    # Print this\n",
    "    print(\"Accuracy on test set using\", i, \"features: \", acc_score)\n",
    "    # Append to the list\n",
    "    acc_scores.append(acc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4803028e-e75f-4c1b-aa86-aee0b3bf6055",
   "metadata": {},
   "source": [
    "# Estimating accuracy score on test set using RFE by using different number of features\n",
    "estimator = DecisionTreeClassifier()\n",
    "acc_scores = []\n",
    "f1_scores = []\n",
    "for i in range(1, 33):\n",
    "    selector = RFE(estimator,n_features_to_select=i)\n",
    "    selector = selector.fit(X_train_normalized, y_train)\n",
    "    supp = selector.get_support()\n",
    "\n",
    "    predicted = selector.predict(X_test_normalized)\n",
    "    acc_score = accuracy_score(y_test, predicted)\n",
    "    acc_scores.append(acc_score)\n",
    "    \n",
    "\n",
    "best = 1\n",
    "for item1 in acc_scores:\n",
    "    if item1 > acc_scores[best - 1]:\n",
    "        best = acc_scores.index(item1) + 1\n",
    "plt.grid()\n",
    "plt.xlabel('# No. of features')\n",
    "plt.ylabel('Accuracy score on test set')\n",
    "plt.plot(range(1, 33), acc_scores, marker = 'o', color = 'lightblue', markeredgewidth = 1 ,markeredgecolor = 'lightblue', markerfacecolor = 'None')\n",
    "plt.plot(best, acc_scores[best-1], marker = 'o', markerfacecolor = 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56e6f4e-15d6-4de6-9cdb-02b5673367d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of features that has the maximisation performance\n",
    "# print(\"The number of features for best accuracy score:\", best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3b4c43-cc6b-47ca-8e7e-82214ab22fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Logistic Regression model\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train_normalized, y_train)\n",
    "# Doing predictions on train and test set\n",
    "y_hat_train = model.predict(X_train_normalized)\n",
    "y_hat_test = model.predict(X_test_normalized)\n",
    "# Evaluate the performance of the trained model\n",
    "print(\"Accuracy score on training set: \", accuracy_score(y_train, y_hat_train))\n",
    "print(\"Accuracy score on testing set: \", accuracy_score(y_test, y_hat_test))\n",
    "# Checking confusion matrix\n",
    "print(\"Confusion matrix on test set: \")\n",
    "print(confusion_matrix(y_test, y_hat_test))\n",
    "print(\"Confusion matrix on train set: \")\n",
    "print(confusion_matrix(y_train, y_hat_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2569803-38ca-467a-b77c-71c20d539c98",
   "metadata": {},
   "source": [
    "### KNN Classifier Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "720d27af-4bcc-4bf3-a62e-784b363b6b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3e73925c-201f-4062-92b9-34beffb3bb68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"â¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â¾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(n_neighbors=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_neighbors=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=1)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the KNN classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Build a KNN classifier model\n",
    "clf_knn = KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "# Train the model with the training data with new features selected\n",
    "clf_knn.fit(X_train_normalized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "bb8502fd-3f91-4cba-afca-d918be5846ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score for testing is: 0.7889699179580675\n",
      "The f1 score for testing is: 0.6995457495133031\n"
     ]
    }
   ],
   "source": [
    "y_pred_new = clf_knn.predict(X_test_normalized)\n",
    "accuracy = accuracy_score(y_test, y_pred_new)\n",
    "print(\"The accuracy score for testing is:\", accuracy)\n",
    "print(\"The f1 score for testing is:\", f1_score(y_test, y_pred_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a48968ab-3398-4d74-8aea-9f91443de2c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score for training is: 1.0\n",
      "The f1 score for training is: 1.0\n"
     ]
    }
   ],
   "source": [
    "y_pred_train_new = clf_knn.predict(X_train_normalized)\n",
    "print(\"The accuracy score for training is:\", accuracy_score(y_train, y_pred_train_new))\n",
    "print(\"The f1 score for training is:\", f1_score(y_train, y_pred_train_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c6bd914f-6232-462e-aece-9f4598292024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best K value:  15\n",
      "The accuracy: 0.8129\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parameter_grid = {'n_neighbors': range(1,33)}\n",
    "knn_clf = KNeighborsClassifier()\n",
    "gs_knn = GridSearchCV(knn_clf, parameter_grid, cv=5, scoring='accuracy')\n",
    "gs_knn.fit(X_train_normalized, y_train)\n",
    "\n",
    "print('Best K value: ', gs_knn.best_params_['n_neighbors'])\n",
    "print('The accuracy: %.4f\\n' % gs_knn.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f0b3d1-750d-4bb7-8bd5-f075b753bcac",
   "metadata": {},
   "source": [
    "# Visualise the performance change with respect to K using a line chart\n",
    "import numpy as np\n",
    "k_values = gs_knn.cv_results_['param_n_neighbors'].data\n",
    "mean_test_scores = gs_knn.cv_results_['mean_test_score']\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(k_values, mean_test_scores, marker='o')\n",
    "plt.title('KNN Hyperparameter Tuning with Grid Search')\n",
    "plt.xlabel('Number of K')\n",
    "plt.ylabel('Mean Accuracy')\n",
    "plt.xticks(np.arange(1, 33, step=1))\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "cce0a52b-b8b1-4ca3-b705-703bfa06538c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score is: 0.8067456700091158\n",
      "The f1 score is: 0.6849925705794947\n"
     ]
    }
   ],
   "source": [
    "#Get the metrics for the best case:\n",
    "best_clf = KNeighborsClassifier(n_neighbors = 15)\n",
    "best_clf.fit(X_train_normalized, y_train)\n",
    "y_for_pred = best_clf.predict(X_test_normalized)\n",
    "print(\"The accuracy score is:\", accuracy_score(y_test, y_for_pred))\n",
    "print(\"The f1 score is:\", f1_score(y_test, y_for_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c0039fb6-4e6b-4c84-8c1e-be8dddf7c861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score is: 0.8263445761166819\n",
      "The f1 score is: 0.7233115468409587\n"
     ]
    }
   ],
   "source": [
    "# Run the model with l1 metrics:\n",
    "knn_l1 = KNeighborsClassifier(n_neighbors=15, metric='l1')\n",
    "knn_l1.fit(X_train_normalized, y_train)\n",
    "y_l1 = knn_l1.predict(X_test_normalized)\n",
    "print(\"The accuracy score is:\", accuracy_score(y_test, y_l1))\n",
    "print(\"The f1 score is:\", f1_score(y_test, y_l1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "474d5859-f75f-4b80-a72c-45909436e008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score is: 0.8176845943482224\n",
      "The f1 score is: 0.7101449275362319\n"
     ]
    }
   ],
   "source": [
    "# Run the model with cosine metrics:\n",
    "knn_cosine = KNeighborsClassifier(n_neighbors=15, metric='cosine')\n",
    "knn_cosine.fit(X_train_normalized, y_train)\n",
    "y_cosine = knn_cosine.predict(X_test_normalized)\n",
    "print(\"The accuracy score is:\", accuracy_score(y_test, y_cosine))\n",
    "print(\"The f1 score is:\", f1_score(y_test, y_cosine))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde19422-6bf0-42da-82fe-00717fd4fd6c",
   "metadata": {},
   "source": [
    "### Random Forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "08d5c2f4-cb3b-4bb8-a439-3687493acb8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score is: 0.9694621695533272\n",
      "The f1 score is: 0.9598562013181547\n"
     ]
    }
   ],
   "source": [
    "# Create and train a Random Forest classifier model\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train_normalized, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "rf_y_pred = rf.predict(X_test_normalized)\n",
    "rf_accuracy = accuracy_score(y_test, rf_y_pred)\n",
    "rf_f1 = f1_score(y_test, rf_y_pred)\n",
    "print('The accuracy score is:', rf_accuracy)\n",
    "print('The f1 score is:', rf_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "eedee0af-2fb7-40f5-b9e3-b927791ca0d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set using 1 features: 0.7219690063810392\n",
      "Accuracy on test set using 2 features: 0.8842297174111212\n",
      "Accuracy on test set using 3 features: 0.9443938012762079\n",
      "Accuracy on test set using 4 features: 0.96718322698268\n",
      "Accuracy on test set using 5 features: 0.9685505925250684\n",
      "Accuracy on test set using 6 features: 0.9726526891522334\n",
      "Accuracy on test set using 7 features: 0.9717411121239745\n",
      "Accuracy on test set using 8 features: 0.9726526891522334\n",
      "Accuracy on test set using 9 features: 0.9731084776663628\n",
      "Accuracy on test set using 10 features: 0.9726526891522334\n",
      "Accuracy on test set using 11 features: 0.9721969006381039\n",
      "Accuracy on test set using 12 features: 0.9721969006381039\n",
      "Accuracy on test set using 13 features: 0.9721969006381039\n",
      "Accuracy on test set using 14 features: 0.9717411121239745\n",
      "Accuracy on test set using 15 features: 0.9731084776663628\n",
      "Accuracy on test set using 16 features: 0.9726526891522334\n",
      "Accuracy on test set using 17 features: 0.9721969006381039\n",
      "Accuracy on test set using 18 features: 0.9735642661804923\n",
      "Accuracy on test set using 19 features: 0.9726526891522334\n",
      "Accuracy on test set using 20 features: 0.9721969006381039\n",
      "Accuracy on test set using 21 features: 0.9726526891522334\n",
      "Accuracy on test set using 22 features: 0.971285323609845\n",
      "Accuracy on test set using 23 features: 0.971285323609845\n",
      "Accuracy on test set using 24 features: 0.9721969006381039\n",
      "Accuracy on test set using 25 features: 0.9721969006381039\n",
      "Accuracy on test set using 26 features: 0.9721969006381039\n",
      "Accuracy on test set using 27 features: 0.9708295350957156\n",
      "Accuracy on test set using 28 features: 0.9717411121239745\n",
      "Accuracy on test set using 29 features: 0.971285323609845\n",
      "Accuracy on test set using 30 features: 0.9708295350957156\n",
      "Accuracy on test set using 31 features: 0.9703737465815861\n",
      "Accuracy on test set using 32 features: 0.9690063810391978\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "acc_scores = []\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "for i in range(1, 33):\n",
    "    rfe_new = RFE(estimator=rf, n_features_to_select=i)\n",
    "    rfe_new.fit(X_train_normalized, y_train)\n",
    "    y_pred = rfe_new.predict(X_test_normalized)\n",
    "    acc_score = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy on test set using {i} features: {acc_score}\")\n",
    "    acc_scores.append(acc_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff3b5ad-2542-4e10-8ffb-66d0d90ba479",
   "metadata": {},
   "source": [
    "# Estimating accuracy score on test set using RFE by using different number of features\n",
    "estimator = RandomForestClassifier()\n",
    "acc_scores = []\n",
    "for i in range(1, 33):\n",
    "    selector = RFE(estimator,n_features_to_select=i)\n",
    "    selector = selector.fit(X_train_normalized, y_train)\n",
    "    supp = selector.get_support()\n",
    "\n",
    "    predicted = selector.predict(X_test_normalized)\n",
    "    acc_score = accuracy_score(y_test, predicted)\n",
    "    acc_scores.append(acc_score)\n",
    "    \n",
    "\n",
    "best = 1\n",
    "for item1 in acc_scores:\n",
    "    if item1 > acc_scores[best - 1]:\n",
    "        best = acc_scores.index(item1) + 1\n",
    "plt.grid()\n",
    "plt.xlabel('# No. of features')\n",
    "plt.ylabel('Accuracy score on test set')\n",
    "plt.plot(range(1, 33), acc_scores, marker = 'o', color = 'lightblue', markeredgewidth = 1 ,markeredgecolor = 'lightblue', markerfacecolor = 'None')\n",
    "plt.plot(best, acc_scores[best-1], marker = 'o', markerfacecolor = 'red')\n",
    "print(\"The best number of features for accuracy score is:\", best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "992f3a4b-7f42-4726-a86a-e1acee9c53b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy: 0.9594348222424794\n",
      "The F1 Score: 0.9593800823475592\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "xgb_clf = xgb.XGBClassifier()\n",
    "xgb_clf.fit(X_train_normalized, y_train)\n",
    "xgb_y_pred = xgb_clf.predict(X_test_normalized)\n",
    "\n",
    "# Evaluate the model: \n",
    "xgb_accuracy = accuracy_score(y_test, xgb_y_pred)\n",
    "xgb_f1 = f1_score(y_test, xgb_y_pred, average='weighted')\n",
    "\n",
    "print('The Accuracy:', xgb_accuracy)\n",
    "print('The F1 Score:', xgb_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "cbce6ff9-0c44-4981-acf2-99d1673bae1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Best parameters: {'colsample_bytree': 1.0, 'learning_rate': 0.01, 'max_depth': 9, 'min_child_weight': 1, 'n_estimators': 300, 'subsample': 1.0}\n",
      "Best Model Accuracy: 0.9721969006381039\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 6, 9],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'min_child_weight': [1, 5, 10],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Grid Search to tune the parameter \n",
    "grid_search = GridSearchCV(xgb.XGBClassifier(random_state=42), param_grid, \n",
    "                           scoring='accuracy', cv=3, verbose=1, n_jobs=-1)\n",
    "grid_search.fit(X_train_normalized, y_train)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Evaluate best model\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test_normalized)\n",
    "print(\"Best Model Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c1084a2c-0b3b-4b63-9b61-0cb835e2ca63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import shap "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "425503b6-0b30-4056-a1e1-cd6e09d4b779",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-18 11:18:20.823 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.866 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /Users/trangnguyen/anaconda3/lib/python3.11/site-packages/ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-03-18 11:18:20.866 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.867 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.867 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.867 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.867 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.867 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.867 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "st.write(\"\"\"\n",
    "# Fraud Transaction Detection App\n",
    "\n",
    "This app helps to detect illegal transaction\n",
    "\"\"\")\n",
    "st.write('---')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2dcab38b-b03d-49ac-80a4-3af0d1dc88b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-18 11:18:20.869 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.870 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeltaGenerator(_root_container=1, _parent=DeltaGenerator())"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sidebar\n",
    "# Header of Specify Input Parameters\n",
    "st.sidebar.header('Specify Input Parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e27b9490-1238-4658-a5a3-873b94117777",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-18 11:18:20.876 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.876 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.876 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.877 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.877 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.877 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.877 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.877 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.877 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.878 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.878 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.878 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.878 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.878 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.878 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.878 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.879 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.879 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.879 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.879 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.879 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.879 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.879 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.880 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.880 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.880 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.880 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.880 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.880 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.881 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.881 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.881 Session state does not function when running a script without `streamlit run`\n",
      "2025-03-18 11:18:20.881 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.881 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.881 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.881 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.882 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.882 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.882 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.882 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.882 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.882 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.882 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.883 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.883 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.883 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.883 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.883 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.883 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.883 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.883 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.884 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.884 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.884 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.884 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.884 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.884 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.884 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.884 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.884 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.885 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.885 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.885 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.885 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.885 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.885 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.885 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.886 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.886 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.886 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.886 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.886 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.886 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.886 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.886 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.887 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.887 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.887 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.887 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.887 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.887 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.887 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.887 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.887 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.888 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.888 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.888 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.888 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.888 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.888 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.888 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.889 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.889 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.890 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.890 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.890 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.890 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.904 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-18 11:18:20.904 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "\n",
    "def user_input_features():\n",
    "    st.sidebar.header(\"User Input Features\")\n",
    "\n",
    "    # Numerical Inputs\n",
    "    Age = st.sidebar.slider('Age', min_value=0, max_value=100, value=10)\n",
    "    NumDependents = st.sidebar.slider('Number of Dependents', min_value=0, max_value=10, value=1)\n",
    "    UserTenure = st.sidebar.slider('User Tenure (Months)', min_value=0, max_value=240, value=12)\n",
    "    Income = st.sidebar.slider('User Income', min_value=0, max_value=1000000, value=20000)\n",
    "    Expenditure = st.sidebar.slider('Expenditure', min_value=0, max_value=1000000, value=20000)\n",
    "\n",
    "    # Categorical Inputs (Using selectbox)\n",
    "    Gender = st.sidebar.selectbox('Gender', ['Male', 'Female', 'Other'])\n",
    "    Occupation = st.sidebar.selectbox('Occupation', ['Student', 'Professional', 'Self-Employed', 'Retired'])\n",
    "    EducationLevel = st.sidebar.selectbox('Education Level', ['High School', 'Bachelors', 'Masters', 'PhD'])\n",
    "    MaritalStatus = st.sidebar.selectbox('Marital Status', ['Single', 'Married', 'Divorced', 'Widowed'])\n",
    "    TransactionType = st.sidebar.selectbox('Transaction Type', ['Online', 'In-store'])\n",
    "    DeviceType = st.sidebar.selectbox('Device Type', ['Mobile', 'Desktop', 'Tablet'])\n",
    "    # Transaction Amount \n",
    "    TransactionAmount = st.sidebar.number_input('Transaction Amount ($)', min_value=0.0, max_value=10000.0, value=50.0)\n",
    "\n",
    "    # Transaction Date \n",
    "    TransactionDate = st.sidebar.date_input('Transaction Date')\n",
    "\n",
    "    # Terrorism Flag \n",
    "    Terrorism = st.sidebar.checkbox('Terrorism Or Not')\n",
    "\n",
    "    # Latitude & Longitude (Handling missing values)\n",
    "    Latitude = st.sidebar.number_input('Latitude', value=0.0, format=\"%.6f\")\n",
    "    Longitude = st.sidebar.number_input('Longitude', value=0.0, format=\"%.6f\")\n",
    "\n",
    "    # Create DataFrame\n",
    "    data = {\n",
    "        'Age': Age,\n",
    "        'NumDependents': NumDependents,\n",
    "        'UserTenure': UserTenure,\n",
    "        'Gender': Gender,\n",
    "        'Occupation': Occupation,\n",
    "        'EducationLevel': EducationLevel,\n",
    "        'MaritalStatus': MaritalStatus,\n",
    "        'Income': Income,\n",
    "        'Expenditure': Expenditure,\n",
    "        'TransactionType': TransactionType,\n",
    "        'DeviceType': DeviceType,\n",
    "        'TransactionAmount': TransactionAmount,\n",
    "        'TransactionDate': str(TransactionDate),\n",
    "        'Terrorism': int(Terrorism),\n",
    "        'Latitude': Latitude,\n",
    "        'Longitude': Longitude\n",
    "    }\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    return pd.DataFrame(data, index=[0])\n",
    "\n",
    "\n",
    "# Run function and display user inputs\n",
    "input_features = user_input_features()\n",
    "st.write(\"User Input Features:\", input_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6844ed53-a7c1-414b-8e2f-95ec981a41f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
      "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://10.126.226.36:8501\u001b[0m\n",
      "\u001b[0m\n",
      "2025-03-18 11:18:23.240 Uncaught app execution\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/trangnguyen/anaconda3/lib/python3.11/site-packages/streamlit/runtime/scriptrunner/exec_code.py\", line 121, in exec_func_with_error_handling\n",
      "    result = func()\n",
      "             ^^^^^^\n",
      "  File \"/Users/trangnguyen/anaconda3/lib/python3.11/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 593, in code_to_exec\n",
      "    exec(code, module.__dict__)\n",
      "  File \"/Users/trangnguyen/Documents/GitHub/PersonalPrj/project.py\", line 21, in <module>\n",
      "    get_ipython().run_line_magic('matplotlib', 'inline')\n",
      "    ^^^^^^^^^^^\n",
      "NameError: name 'get_ipython' is not defined\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "!streamlit run project.py --server.enableCORS false --server.enableXsrfProtection false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50355671-f01c-48e4-8890-99f6f7965bea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf096889-3e84-46b2-9f6b-0f609d113d82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
